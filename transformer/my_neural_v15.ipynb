{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformerベースのモデルを定義してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "import utils\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42) # 乱数生成シード\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Grab a GPU if there is one\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using {} device: {}\".format(device, torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorDataTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, transformer_model='bert-base-uncased'):\n",
    "        super(SensorDataTransformer, self).__init__()\n",
    "        self.config = BertConfig.from_pretrained(transformer_model)\n",
    "        self.config.hidden_size = input_dim\n",
    "        self.transformer = BertModel(self.config)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Transformer expects inputs of shape (batch_size, seq_length, input_dim)\n",
    "        # Here we need to rearrange the input to match BERT's expected input shape\n",
    "        x = x.permute(1, 0, 2)  # shape: (seq_length, batch_size, input_dim)\n",
    "        outputs = self.transformer(inputs_embeds=x)\n",
    "        pooled_output = outputs.pooler_output  # shape: (batch_size, hidden_size)\n",
    "        return self.fc(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaiha\\anaconda3\\envs\\labo_Okita\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "class SensorTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, output_dim):\n",
    "        super(SensorTransformer, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_dim)\n",
    "        x = self.input_linear(x)  # (batch_size, seq_len, model_dim)\n",
    "        x = self.pos_encoder(x.permute(1, 0, 2))  # (seq_len, batch_size, model_dim)\n",
    "        x = self.transformer_encoder(x)  # (seq_len, batch_size, model_dim)\n",
    "        x = x.permute(1, 0, 2)  # (batch_size, seq_len, model_dim)\n",
    "        x = x[:, -1, :]  # (batch_size, model_dim)\n",
    "        x = self.fc_out(x)  # (batch_size, output_dim)\n",
    "        return x\n",
    "\n",
    "# モデルのインスタンス化\n",
    "input_dim = 10\n",
    "model_dim = 64\n",
    "num_heads = 8\n",
    "num_layers = 4\n",
    "output_dim = 1  # 例えば、回帰タスクの場合\n",
    "\n",
    "model = SensorTransformer(input_dim, model_dim, num_heads, num_layers, output_dim)\n",
    "\n",
    "# ダミーセンサーデータの作成（バッチサイズ=32、シーケンス長=50、特徴数=10）\n",
    "sensor_data = torch.randn(32, 50, 10)\n",
    "\n",
    "# フォワードパスの実行\n",
    "output = model(sensor_data)\n",
    "print(f'Output shape: {output.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SensorTransformer(\n",
      "  (input_linear): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (pos_encoder): PositionalEncoding()\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc_out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo_Okita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
