{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "äº‹å‰å­¦ç¿’ãªã—ã§æœ€åˆã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã—ã¦ã¿ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertModel, BertConfig\n",
    "import seaborn as sns\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "#import utils\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42) # ä¹±æ•°ç”Ÿæˆã‚·ãƒ¼ãƒ‰\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Grab a GPU if there is one\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using {} device: {}\".format(device, torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196072, 500)\n",
      "(196072,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fold = \"../../train_raw_npy/\"\n",
    "acc_x = np.loadtxt(\"../../train_raw/Acc_x.txt\")\n",
    "label = np.load(f\"{fold}sampled_label.npy\")\n",
    "\n",
    "print(acc_x.shape)\n",
    "print(label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max index after shifting: 5104\n",
      "Vocab size: 5105\n",
      "Sample discrete data: [[4091 4092 4099 ... 1129 1375 1485]\n",
      " [1559 1577 1382 ... 1602 1609 1585]\n",
      " [1499 1394 1255 ... 4283 4272 4299]\n",
      " ...\n",
      " [2760 2514 3253 ... 4438 3632 1623]\n",
      " [ 728 2148 2772 ... 3927 4211 4065]\n",
      " [2219 2147 3659 ... 1336 2174 3062]]\n",
      "Discrete data range: 104 to 5104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# åˆ†å¸ƒã®è¦–è¦šåŒ–\\nplt.figure(figsize=(12, 6))\\nsns.histplot(discrete_data.flatten(), bins=num_bins, kde=False)\\nplt.title(f\"Distribution of Discretized Accelerometer X-axis Data ({num_bins} bins, equal-frequency)\")\\nplt.xlabel(\"Discrete Value\")\\nplt.ylabel(\"Frequency\")\\nplt.show()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ãƒ“ãƒ³ã®æ•°ã‚’è¨­å®š\n",
    "num_bins = 5000  # å¿…è¦ã«å¿œã˜ã¦èª¿æ•´\n",
    "\n",
    "# ãƒ“ãƒ³ã®å¢ƒç•Œã‚’ç­‰é »åº¦ã§è¨­å®š\n",
    "bins = np.percentile(acc_x, np.linspace(0, 100, num_bins + 1))\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ“ãƒ³ã«åˆ†å‰²\n",
    "discrete_data = np.digitize(acc_x, bins) - 1  # ãƒ“ãƒ³ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã—ã€0ã‹ã‚‰å§‹ã¾ã‚‹ã‚ˆã†ã«èª¿æ•´\n",
    "\n",
    "# äºˆç´„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã‚·ãƒ•ãƒˆ\n",
    "discrete_data += 104\n",
    "\n",
    "# æœ€å¤§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç¢ºèª\n",
    "max_index = discrete_data.max()\n",
    "print(f\"Max index after shifting: {max_index}\")\n",
    "\n",
    "# vocab_sizeã‚’ç¢ºèªï¼ˆã‚·ãƒ•ãƒˆå¾Œã®æœ€å¤§å€¤ã‚’è€ƒæ…®ï¼‰\n",
    "vocab_size = max_index + 1\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "\n",
    "# ç¢ºèªã®ãŸã‚ã®ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿\n",
    "print(\"Sample discrete data:\", discrete_data[:10])\n",
    "print(\"Discrete data range:\", np.min(discrete_data), \"to\", np.max(discrete_data))\n",
    "\n",
    "\"\"\"# åˆ†å¸ƒã®è¦–è¦šåŒ–\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(discrete_data.flatten(), bins=num_bins, kde=False)\n",
    "plt.title(f\"Distribution of Discretized Accelerometer X-axis Data ({num_bins} bins, equal-frequency)\")\n",
    "plt.xlabel(\"Discrete Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\"\"\"\n",
    "\n",
    "# é›¢æ•£åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜\n",
    "#np.save(\"train_token_ids_rebinned.npy\", discrete_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 500)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "#èª¬æ˜å¤‰æ•°\n",
    "X = discrete_data\n",
    "#ç›®çš„å¤‰æ•°\n",
    "Y = label\n",
    "\n",
    "#ãŠã—ã‚Š3ä¸‡ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†  \n",
    "X_30000 = X[-40000:-10000,:]\n",
    "label_30000 = label[-40000:-10000]\n",
    "print(X_30000.shape)\n",
    "print(label_30000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"# X_30000ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®é »åº¦ã‚’è¦‹ã¦ã¿ã‚‹\\nsns.histplot(X_30000.flatten(), bins=num_bins, kde=False)\\nplt.title(f\"Distribution of Discretized Accelerometer X-axis Data ({num_bins} bins, equal-frequency)\")\\nplt.xlabel(\"Discrete Value\")\\nplt.ylabel(\"Frequency\")\\nplt.show()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"# X_30000ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®é »åº¦ã‚’è¦‹ã¦ã¿ã‚‹\n",
    "sns.histplot(X_30000.flatten(), bins=num_bins, kde=False)\n",
    "plt.title(f\"Distribution of Discretized Accelerometer X-axis Data ({num_bins} bins, equal-frequency)\")\n",
    "plt.xlabel(\"Discrete Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "float64\n",
      "int32\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(X_30000.dtype)\n",
    "print(label_30000.dtype)\n",
    "X_30000 =X_30000.astype(np.int32)\n",
    "label_30000 = label_30000.astype(np.int32)\n",
    "print(X_30000.dtype)\n",
    "print(label_30000.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (24000, 500)\n",
      "Test data shape: (6000, 500)\n",
      "Train label shape: (24000,)\n",
      "Test label shape: (6000,)\n",
      "1    4235\n",
      "4    3917\n",
      "7    3893\n",
      "6    3582\n",
      "2    3010\n",
      "5    2964\n",
      "8    1445\n",
      "3     954\n",
      "Name: count, dtype: int64\n",
      "1    1041\n",
      "7     964\n",
      "4     960\n",
      "6     926\n",
      "5     774\n",
      "2     719\n",
      "8     373\n",
      "3     243\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "train_x, test_x, train_label, test_label = train_test_split(X_30000, label_30000, test_size=0.2,random_state=40)\n",
    "\n",
    "# çµæœã®ç¢ºèª\n",
    "print(f\"Train data shape: {train_x.shape}\")\n",
    "print(f\"Test data shape: {test_x.shape}\")\n",
    "print(f\"Train label shape: {train_label.shape}\")\n",
    "print(f\"Test label shape: {test_label.shape}\")\n",
    "print(pd.Series(train_label).value_counts())\n",
    "print(pd.Series(test_label).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.data[idx], dtype=torch.long)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        # [CLS] ã¨ [SEP] ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ \n",
    "        input_ids = torch.cat([torch.tensor([101]), input_ids, torch.tensor([102])])\n",
    "\n",
    "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5105"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6 4 ... 5 5 5]\n",
      "[3 5 3 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(train_label)\n",
    "train_label -=1\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 4 3 ... 6 6 7]\n",
      "[6 3 2 ... 5 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(test_label)\n",
    "test_label -=1\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# BERTã®è¨­å®šã‚’å®šç¾©\\nconfig = BertConfig(\\n    vocab_size=vocab_size,  # ãƒ“ãƒ³ã®æ•° + 104\\n    hidden_size=768,\\n    num_hidden_layers=6,\\n    num_attention_heads=12,\\n    intermediate_size=3072,\\n    max_position_embeddings=502,  # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•· + 1 (CLSãƒˆãƒ¼ã‚¯ãƒ³)\\n    type_vocab_size=2  # é€šå¸¸ã€2ã¤ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ— (ã‚¿ã‚¤ãƒ—0ã¨ã‚¿ã‚¤ãƒ—1) ã‚’ä½¿ç”¨\\n)\\nfrom transformers import BertConfig, BertForMaskedLM\\n# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\\nmodel = BertForMaskedLM(config)\\n#model.bert.embeddings = CustomBertEmbeddings(config)\\nprint(model)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ä½œæˆ\n",
    "train_dataset = SensorDataset(train_x, train_label)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "eval_dataset = SensorDataset(test_x, test_label)\n",
    "eval_dataloader = DataLoader(eval_dataset)\n",
    "\"\"\"# BERTã®è¨­å®šã‚’å®šç¾©\n",
    "config = BertConfig(\n",
    "    vocab_size=vocab_size,  # ãƒ“ãƒ³ã®æ•° + 104\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=502,  # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•· + 1 (CLSãƒˆãƒ¼ã‚¯ãƒ³)\n",
    "    type_vocab_size=2  # é€šå¸¸ã€2ã¤ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ— (ã‚¿ã‚¤ãƒ—0ã¨ã‚¿ã‚¤ãƒ—1) ã‚’ä½¿ç”¨\n",
    ")\n",
    "from transformers import BertConfig, BertForMaskedLM\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
    "model = BertForMaskedLM(config)\n",
    "#model.bert.embeddings = CustomBertEmbeddings(config)\n",
    "print(model)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(5105, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "# BERTã®è¨­å®šã‚’å®šç¾©\n",
    "config = BertConfig(\n",
    "    vocab_size=vocab_size,  # å¿…è¦ã«å¿œã˜ã¦èª¿æ•´\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=6, # 9ãŒé™ç•Œãªã®ã§ã¯ï¼Ÿ(vram12gbã§ã¯)\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=512,\n",
    "    num_labels=8,  # 8ã‚¯ãƒ©ã‚¹åˆ†é¡\n",
    ")\n",
    "\n",
    "# BERTãƒ¢ãƒ‡ãƒ«ã‚’8ã‚¯ãƒ©ã‚¹åˆ†é¡ç”¨ã«å®šç¾©\n",
    "model = BertForSequenceClassification(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaiha\\anaconda3\\envs\\labo_Okita\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5273c3437374460aa9265e8ccc04feb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0563, 'grad_norm': 3.1014015674591064, 'learning_rate': 4.7777777777777784e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9142, 'grad_norm': 7.507814884185791, 'learning_rate': 4.555555555555556e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215b666d7cc241c795f92322498c60fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.611985683441162, 'eval_runtime': 18.9229, 'eval_samples_per_second': 317.076, 'eval_steps_per_second': 39.635, 'epoch': 0.33}\n",
      "{'loss': 1.6425, 'grad_norm': 5.710427284240723, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.4}\n",
      "{'loss': 1.5745, 'grad_norm': 10.342754364013672, 'learning_rate': 4.111111111111111e-05, 'epoch': 0.53}\n",
      "{'loss': 1.5339, 'grad_norm': 6.573219299316406, 'learning_rate': 3.888888888888889e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfab459bf02407eb54d400723095e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4952894449234009, 'eval_runtime': 20.3602, 'eval_samples_per_second': 294.692, 'eval_steps_per_second': 36.836, 'epoch': 0.67}\n",
      "{'loss': 1.5375, 'grad_norm': 3.9385385513305664, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.8}\n",
      "{'loss': 1.4486, 'grad_norm': 9.228249549865723, 'learning_rate': 3.444444444444445e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59f7260a2d34fb585d7e6a68cf40e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4346240758895874, 'eval_runtime': 20.2138, 'eval_samples_per_second': 296.827, 'eval_steps_per_second': 37.103, 'epoch': 1.0}\n",
      "{'loss': 1.4255, 'grad_norm': 11.086310386657715, 'learning_rate': 3.222222222222223e-05, 'epoch': 1.07}\n",
      "{'loss': 1.3931, 'grad_norm': 8.170818328857422, 'learning_rate': 3e-05, 'epoch': 1.2}\n",
      "{'loss': 1.3797, 'grad_norm': 13.066079139709473, 'learning_rate': 2.777777777777778e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6020f12b3b41c7a313032f07c17db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3841625452041626, 'eval_runtime': 20.3641, 'eval_samples_per_second': 294.636, 'eval_steps_per_second': 36.83, 'epoch': 1.33}\n",
      "{'loss': 1.3595, 'grad_norm': 15.026509284973145, 'learning_rate': 2.5555555555555554e-05, 'epoch': 1.47}\n",
      "{'loss': 1.3859, 'grad_norm': 7.65357780456543, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132fa34a5a794fb08edd4e8c4a778e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3595472574234009, 'eval_runtime': 20.2267, 'eval_samples_per_second': 296.638, 'eval_steps_per_second': 37.08, 'epoch': 1.67}\n",
      "{'loss': 1.3561, 'grad_norm': 9.646368980407715, 'learning_rate': 2.111111111111111e-05, 'epoch': 1.73}\n",
      "{'loss': 1.2992, 'grad_norm': 6.726350784301758, 'learning_rate': 1.888888888888889e-05, 'epoch': 1.87}\n",
      "{'loss': 1.3375, 'grad_norm': 8.690300941467285, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6465533d6d4443b1966eea9d7812e04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3243721723556519, 'eval_runtime': 20.4239, 'eval_samples_per_second': 293.773, 'eval_steps_per_second': 36.722, 'epoch': 2.0}\n",
      "{'loss': 1.2733, 'grad_norm': 4.490359306335449, 'learning_rate': 1.4444444444444444e-05, 'epoch': 2.13}\n",
      "{'loss': 1.2239, 'grad_norm': 9.885929107666016, 'learning_rate': 1.2222222222222222e-05, 'epoch': 2.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd389163fc634ec2802c1e0e37bf87eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3117179870605469, 'eval_runtime': 18.9516, 'eval_samples_per_second': 316.597, 'eval_steps_per_second': 39.575, 'epoch': 2.33}\n",
      "{'loss': 1.25, 'grad_norm': 6.758425712585449, 'learning_rate': 1e-05, 'epoch': 2.4}\n",
      "{'loss': 1.2055, 'grad_norm': 19.807043075561523, 'learning_rate': 7.777777777777777e-06, 'epoch': 2.53}\n",
      "{'loss': 1.2173, 'grad_norm': 8.534171104431152, 'learning_rate': 5.555555555555556e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10cdf44baf94a07822ab981707bc125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2983232736587524, 'eval_runtime': 19.0474, 'eval_samples_per_second': 315.004, 'eval_steps_per_second': 39.376, 'epoch': 2.67}\n",
      "{'loss': 1.2291, 'grad_norm': 8.149041175842285, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.8}\n",
      "{'loss': 1.2206, 'grad_norm': 10.221332550048828, 'learning_rate': 1.1111111111111112e-06, 'epoch': 2.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7312f23bbdd240dd8491bc684173079a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.287358045578003, 'eval_runtime': 20.2271, 'eval_samples_per_second': 296.632, 'eval_steps_per_second': 37.079, 'epoch': 3.0}\n",
      "{'train_runtime': 915.9493, 'train_samples_per_second': 78.607, 'train_steps_per_second': 2.456, 'train_loss': 1.4175110100640191, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2250, training_loss=1.4175110100640191, metrics={'train_runtime': 915.9493, 'train_samples_per_second': 78.607, 'train_steps_per_second': 2.456, 'total_flos': 9352371034368000.0, 'train_loss': 1.4175110100640191, 'epoch': 3.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_steps=0,\n",
    "    save_total_limit=0,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®å®šç¾©\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3020f55ad5744dd0b644a7586c1a2918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.49      0.55      1041\n",
      "           2       0.39      0.55      0.46       719\n",
      "           3       0.95      0.95      0.95       243\n",
      "           4       0.68      0.78      0.73       960\n",
      "           5       0.43      0.48      0.46       774\n",
      "           6       0.48      0.39      0.43       926\n",
      "           7       0.38      0.47      0.42       964\n",
      "           8       0.21      0.01      0.02       373\n",
      "\n",
      "    accuracy                           0.51      6000\n",
      "   macro avg       0.52      0.52      0.50      6000\n",
      "weighted avg       0.51      0.51      0.50      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = trainer.predict(eval_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "# åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ\n",
    "report = classification_report(test_label, preds, target_names=[str(i) for i in range(1, 9)])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del train_dataset\n",
    "del trainer\n",
    "del eval_dataset\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# num_filter_layersã‚’å¢—ã‚„ã—ã¦ã¿ã‚‹  \n",
    "åˆæœŸå€¤ã¯12ã§ã‚ã‚‹ãŒä¸Šã®ä¾‹ã§ã¯6ã«ã—ã¦ã‚ã£ãŸã€‚ã‚‚ã—ã‹ã—ãŸã‚‰ãã®ã›ã„ã§ç²¾åº¦ãŒå‡ºãªã„ã ã‘ãªã®ã‹ã‚‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# BERTã®è¨­å®šã‚’å®šç¾©\\nconfig = BertConfig(\\n    vocab_size=vocab_size,  # ãƒ“ãƒ³ã®æ•° + 104\\n    hidden_size=768,\\n    num_hidden_layers=6,\\n    num_attention_heads=12,\\n    intermediate_size=3072,\\n    max_position_embeddings=502,  # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•· + 1 (CLSãƒˆãƒ¼ã‚¯ãƒ³)\\n    type_vocab_size=2  # é€šå¸¸ã€2ã¤ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ— (ã‚¿ã‚¤ãƒ—0ã¨ã‚¿ã‚¤ãƒ—1) ã‚’ä½¿ç”¨\\n)\\nfrom transformers import BertConfig, BertForMaskedLM\\n# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\\nmodel = BertForMaskedLM(config)\\n#model.bert.embeddings = CustomBertEmbeddings(config)\\nprint(model)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®ä½œæˆ\n",
    "train_dataset = SensorDataset(train_x, train_label)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "eval_dataset = SensorDataset(test_x, test_label)\n",
    "eval_dataloader = DataLoader(eval_dataset)\n",
    "\"\"\"# BERTã®è¨­å®šã‚’å®šç¾©\n",
    "config = BertConfig(\n",
    "    vocab_size=vocab_size,  # ãƒ“ãƒ³ã®æ•° + 104\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=502,  # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•· + 1 (CLSãƒˆãƒ¼ã‚¯ãƒ³)\n",
    "    type_vocab_size=2  # é€šå¸¸ã€2ã¤ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ— (ã‚¿ã‚¤ãƒ—0ã¨ã‚¿ã‚¤ãƒ—1) ã‚’ä½¿ç”¨\n",
    ")\n",
    "from transformers import BertConfig, BertForMaskedLM\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
    "model = BertForMaskedLM(config)\n",
    "#model.bert.embeddings = CustomBertEmbeddings(config)\n",
    "print(model)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(5105, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-9): 10 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "# BERTã®è¨­å®šã‚’å®šç¾©\n",
    "config = BertConfig(\n",
    "    vocab_size=vocab_size,  # å¿…è¦ã«å¿œã˜ã¦èª¿æ•´\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=10, # 10ãŒé™ç•Œãªã®ã§ã¯ï¼Ÿ(vram12gbã§ã¯)\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=512,\n",
    "    num_labels=8,  # 8ã‚¯ãƒ©ã‚¹åˆ†é¡\n",
    ")\n",
    "\n",
    "# BERTãƒ¢ãƒ‡ãƒ«ã‚’8ã‚¯ãƒ©ã‚¹åˆ†é¡ç”¨ã«å®šç¾©\n",
    "model = BertForSequenceClassification(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e21c8c6b9a14ec4ae6e7b544af3b37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0536, 'grad_norm': 2.71994948387146, 'learning_rate': 4.7777777777777784e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0183, 'grad_norm': 4.676105499267578, 'learning_rate': 4.555555555555556e-05, 'epoch': 0.27}\n",
      "{'loss': 2.0127, 'grad_norm': 3.8067429065704346, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.4}\n",
      "{'loss': 2.0243, 'grad_norm': 4.196624755859375, 'learning_rate': 4.111111111111111e-05, 'epoch': 0.53}\n",
      "{'loss': 2.0389, 'grad_norm': 2.929673194885254, 'learning_rate': 3.888888888888889e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e962e7ec694d73bfabf5a04ec049ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0107414722442627, 'eval_runtime': 32.7227, 'eval_samples_per_second': 183.359, 'eval_steps_per_second': 22.92, 'epoch': 0.67}\n",
      "{'loss': 2.012, 'grad_norm': 2.4816131591796875, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.8}\n",
      "{'loss': 2.0159, 'grad_norm': 2.413952350616455, 'learning_rate': 3.444444444444445e-05, 'epoch': 0.93}\n",
      "{'loss': 2.0087, 'grad_norm': 3.337390422821045, 'learning_rate': 3.222222222222223e-05, 'epoch': 1.07}\n",
      "{'loss': 2.0187, 'grad_norm': 2.5023200511932373, 'learning_rate': 3e-05, 'epoch': 1.2}\n",
      "{'loss': 1.8152, 'grad_norm': 6.377017498016357, 'learning_rate': 2.777777777777778e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a4b06d596340398079b6a8f558b6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6860272884368896, 'eval_runtime': 173.2491, 'eval_samples_per_second': 34.632, 'eval_steps_per_second': 4.329, 'epoch': 1.33}\n",
      "{'loss': 1.6614, 'grad_norm': 7.186163425445557, 'learning_rate': 2.5555555555555554e-05, 'epoch': 1.47}\n",
      "{'loss': 1.6076, 'grad_norm': 6.248212814331055, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.6}\n",
      "{'loss': 1.5519, 'grad_norm': 6.305764198303223, 'learning_rate': 2.111111111111111e-05, 'epoch': 1.73}\n",
      "{'loss': 1.4749, 'grad_norm': 4.788961887359619, 'learning_rate': 1.888888888888889e-05, 'epoch': 1.87}\n",
      "{'loss': 1.4868, 'grad_norm': 9.401933670043945, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce69c306b5824b27977e154e89245ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4533944129943848, 'eval_runtime': 172.1621, 'eval_samples_per_second': 34.851, 'eval_steps_per_second': 4.356, 'epoch': 2.0}\n",
      "{'loss': 1.4407, 'grad_norm': 9.720457077026367, 'learning_rate': 1.4444444444444444e-05, 'epoch': 2.13}\n",
      "{'loss': 1.4019, 'grad_norm': 5.269026279449463, 'learning_rate': 1.2222222222222222e-05, 'epoch': 2.27}\n",
      "{'loss': 1.4129, 'grad_norm': 3.9075980186462402, 'learning_rate': 1e-05, 'epoch': 2.4}\n",
      "{'loss': 1.3965, 'grad_norm': 8.5674467086792, 'learning_rate': 7.777777777777777e-06, 'epoch': 2.53}\n",
      "{'loss': 1.3689, 'grad_norm': 7.356326103210449, 'learning_rate': 5.555555555555556e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3cfd1ae73046f18cb800b0266ce219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4132689237594604, 'eval_runtime': 167.0233, 'eval_samples_per_second': 35.923, 'eval_steps_per_second': 4.49, 'epoch': 2.67}\n",
      "{'loss': 1.3802, 'grad_norm': 4.176865100860596, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.8}\n",
      "{'loss': 1.3757, 'grad_norm': 3.233841896057129, 'learning_rate': 1.1111111111111112e-06, 'epoch': 2.93}\n",
      "{'train_runtime': 3071.363, 'train_samples_per_second': 23.442, 'train_steps_per_second': 0.733, 'train_loss': 1.7009070502387154, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2250, training_loss=1.7009070502387154, metrics={'train_runtime': 3071.363, 'train_samples_per_second': 23.442, 'train_steps_per_second': 0.733, 'total_flos': 1.5500788128e+16, 'train_loss': 1.7009070502387154, 'epoch': 3.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    save_steps=0,\n",
    "    save_total_limit=0,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®å®šç¾©\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0890304a13c64b52a0472071d49383aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.45      0.46      1041\n",
      "           2       0.31      0.49      0.38       719\n",
      "           3       0.93      0.91      0.92       243\n",
      "           4       0.68      0.70      0.69       960\n",
      "           5       0.40      0.46      0.43       774\n",
      "           6       0.44      0.39      0.41       926\n",
      "           7       0.34      0.33      0.34       964\n",
      "           8       0.00      0.00      0.00       373\n",
      "\n",
      "    accuracy                           0.46      6000\n",
      "   macro avg       0.45      0.47      0.45      6000\n",
      "weighted avg       0.44      0.46      0.45      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaiha\\anaconda3\\envs\\labo_Okita\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\kaiha\\anaconda3\\envs\\labo_Okita\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\kaiha\\anaconda3\\envs\\labo_Okita\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = trainer.predict(eval_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "# åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ\n",
    "report = classification_report(test_label, preds, target_names=[str(i) for i in range(1, 9)])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_data_loader(data_loader, vocab_size):\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        if input_ids.max() >= vocab_size or labels.max() >= vocab_size:\n",
    "            print(f\"Error: Found out of range index in input_ids or labels. Max value should be less than {vocab_size}.\")\n",
    "            print(f\"Max value in input_ids: {input_ids.max()}\")\n",
    "            print(f\"Max value in labels: {labels.max()}\")\n",
    "            return False\n",
    "\n",
    "        if input_ids.dtype != torch.long or labels.dtype != torch.long:\n",
    "            print(\"Error: Data type mismatch. input_ids and labels should be of type torch.long.\")\n",
    "            print(f\"input_ids dtype: {input_ids.dtype}\")\n",
    "            print(f\"labels dtype: {labels.dtype}\")\n",
    "            return False\n",
    "\n",
    "    print(\"Data validation passed.\")\n",
    "    return True\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã®æ¤œè¨¼\n",
    "validate_data_loader(train_dataloader, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo_Okita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
