{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from diffusers import DDPMScheduler, UNet1DModel, UNet2DModel\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42) # 乱数生成シード\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Grab a GPU if there is one\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using {} device: {}\".format(device, torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Attend-and-Discriminate model based on architecture suggested by Abedin et al.\n",
    "# ------------------------------------------------------------------------\n",
    "# https://github.com/AdelaideAuto-IDLab/Attend-And-Discriminate\n",
    "# ------------------------------------------------------------------------\n",
    "# Adaption by: Marius Bock\n",
    "# Email: marius.bock(at)uni-siegen.de\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def conv1d(ni: int, no: int, ks: int = 1, stride: int = 1, padding: int = 0, bias: bool = True):\n",
    "    \"\"\"\n",
    "    Create and initialize a `nn.Conv1d` layer with spectral normalization.\n",
    "    \"\"\"\n",
    "    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n",
    "    nn.init.kaiming_normal_(conv.weight)\n",
    "    if bias:\n",
    "        conv.bias.data.zero_()\n",
    "    # return spectral_norm(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    # self-attention implementation from https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "    Self attention layer for nd\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_channels: int, div):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        if n_channels > 1:\n",
    "            self.query = conv1d(n_channels, n_channels // div)\n",
    "            self.key = conv1d(n_channels, n_channels // div)\n",
    "        else:\n",
    "            self.query = conv1d(n_channels, n_channels)\n",
    "            self.key = conv1d(n_channels, n_channels)\n",
    "        self.value = conv1d(n_channels, n_channels)\n",
    "        self.gamma = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Notation from https://arxiv.org/pdf/1805.08318.pdf\n",
    "        size = x.size()\n",
    "        x = x.view(*size[:2], -1)\n",
    "        f, g, h = self.query(x), self.key(x), self.value(x)\n",
    "        beta = F.softmax(torch.bmm(f.permute(0, 2, 1).contiguous(), g), dim=1)\n",
    "        o = self.gamma * torch.bmm(h, beta) + x\n",
    "        return o.view(*size).contiguous()\n",
    "\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal attention module from https://dl.acm.org/doi/abs/10.1145/3448083\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(TemporalAttention, self).__init__()\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sm = torch.nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x).squeeze(2)\n",
    "        weights_att = self.sm(out).unsqueeze(2)\n",
    "        context = torch.sum(weights_att * x, 0)\n",
    "        return context\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            filter_num,\n",
    "            filter_size,\n",
    "            enc_num_layers,\n",
    "            enc_is_bidirectional,\n",
    "            dropout,\n",
    "            dropout_rnn,\n",
    "            activation,\n",
    "            sa_div,\n",
    "    ):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, filter_num, (filter_size, 1))\n",
    "        self.conv2 = nn.Conv2d(filter_num, filter_num, (filter_size, 1))\n",
    "        self.conv3 = nn.Conv2d(filter_num, filter_num, (filter_size, 1))\n",
    "        self.conv4 = nn.Conv2d(filter_num, filter_num, (filter_size, 1))\n",
    "\n",
    "        self.activation = nn.ReLU() if activation == \"ReLU\" else nn.Tanh()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.rnn = nn.GRU(\n",
    "            filter_num * input_dim,\n",
    "            hidden_dim,\n",
    "            enc_num_layers,\n",
    "            bidirectional=enc_is_bidirectional,\n",
    "            dropout=dropout_rnn,\n",
    "        )\n",
    "\n",
    "        self.ta = TemporalAttention(hidden_dim)\n",
    "        self.sa = SelfAttention(filter_num, sa_div)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = self.activation(self.conv4(x))\n",
    "\n",
    "        # apply self-attention on each temporal dimension (along sensor and feature dimensions)\n",
    "        refined = torch.cat(\n",
    "            [self.sa(torch.unsqueeze(x[:, :, t, :], dim=3)) for t in range(x.shape[2])],\n",
    "            dim=-1,\n",
    "        )\n",
    "        x = refined.permute(3, 0, 1, 2)\n",
    "        x = x.reshape(x.shape[0], x.shape[1], -1)\n",
    "        x = self.dropout(x)\n",
    "        outputs, h = self.rnn(x)\n",
    "        # apply temporal attention on GRU outputs\n",
    "        out = self.ta(outputs)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_class):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z)\n",
    "\n",
    "\n",
    "class AttendAndDiscriminate(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels,\n",
    "            classes,\n",
    "            hidden_dim=128,\n",
    "            conv_kernels=64,\n",
    "            conv_kernel_size=5,\n",
    "            enc_num_layers=2,\n",
    "            enc_is_bidirectional=False,\n",
    "            dropout=0.5,\n",
    "            dropout_rnn=0.5,\n",
    "            dropout_cls=0.5,\n",
    "            activation='ReLU',\n",
    "            sa_div=1,\n",
    "            gpu='cuda:0'\n",
    "    ):\n",
    "        super(AttendAndDiscriminate, self).__init__()\n",
    "        self.gpu = gpu\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.fe = FeatureExtractor(\n",
    "            channels,\n",
    "            hidden_dim,\n",
    "            conv_kernels,\n",
    "            conv_kernel_size,\n",
    "            enc_num_layers,\n",
    "            enc_is_bidirectional,\n",
    "            dropout,\n",
    "            dropout_rnn,\n",
    "            activation,\n",
    "            sa_div,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_cls)\n",
    "        self.classifier = Classifier(hidden_dim, classes)\n",
    "        self.register_buffer(\n",
    "            \"centers\", (torch.randn(classes, self.hidden_dim).to(self.gpu))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature = self.fe(x)\n",
    "        z = feature.div(\n",
    "            torch.norm(feature, p=2, dim=1, keepdim=True).expand_as(feature)\n",
    "        )\n",
    "        out = self.dropout(feature)\n",
    "        logits = self.classifier(out)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttendAndDiscriminate(\n",
      "  (fe): FeatureExtractor(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "    (conv3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "    (conv4): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "    (activation): ReLU()\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (rnn): GRU(192, 128, num_layers=2, dropout=0.5)\n",
      "    (ta): TemporalAttention(\n",
      "      (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (sm): Softmax(dim=0)\n",
      "    )\n",
      "    (sa): SelfAttention(\n",
      "      (query): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (key): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (value): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (classifier): Classifier(\n",
      "    (fc): Linear(in_features=128, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AttendAndDiscriminate(3, 8)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo_Okita02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
