{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "性能比較  \n",
    "これまでのモデルを検証データで性能比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42) # 乱数生成シード\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Grab a GPU if there is one\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using {} device: {}\".format(device, torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28789, 3, 500)\n",
      "(28789,)\n"
     ]
    }
   ],
   "source": [
    "fold = \"../validation_raw_npy/\"\n",
    "xyz = np.load(f\"{fold}acc_xyz.npy\")\n",
    "label = np.load(f\"{fold}sampled_label.npy\")\n",
    "print(xyz.shape)\n",
    "print(label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU_v5(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=True,\n",
    "            dropout=0.0 # ドロップアウト率を新規追加\n",
    "    ):\n",
    "        super(ConvBNReLU_v5, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=bias),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        if dropout > 0:\n",
    "            self.main.append(nn.Dropout(dropout))\n",
    "\n",
    "        # He初期化\n",
    "        nn.init.kaiming_normal_(self.main[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        if self.main[0].bias is not None:\n",
    "            nn.init.constant_(self.main[0].bias, 0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.main(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class CNN_v5(nn.Module):\n",
    "    def __init__(self, output_size=8, in_channels=3, num_filters_init=8, dropout=0.0):\n",
    "        super(CNN_v5, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            ConvBNReLU_v5(in_channels, num_filters_init, 3,1,1), # 500 -> 500\n",
    "            \n",
    "\n",
    "            ConvBNReLU_v5(num_filters_init, num_filters_init*2, 8,2,3,dropout=dropout ), # 500->250\n",
    "            \n",
    "            ConvBNReLU_v5(num_filters_init*2, num_filters_init*4, 6,2,2,dropout=dropout), # 250 -> 125 (248)\n",
    "            ConvBNReLU_v5(num_filters_init*4, num_filters_init*8,7,2,2, dropout=dropout), # 125 -> 62\n",
    "            ConvBNReLU_v5(num_filters_init*8, num_filters_init*16,6,2,1 , dropout=dropout), # 62 -> 30\n",
    "\n",
    "            ConvBNReLU_v5(num_filters_init*16, num_filters_init*32, 4, 2, 1, dropout=dropout), # 30 -> 15\n",
    "            ConvBNReLU_v5(num_filters_init*32, num_filters_init*64, 3, 2, 1, dropout=dropout), # 15->8\n",
    "\n",
    "            ConvBNReLU_v5(num_filters_init*64, num_filters_init*128, 8,1,0), # 8 -> 1 \n",
    "            #nn.Conv1d(num_filters_init*128, output_size, 1,1,0) #代わりに下の全結合層を導入\n",
    "            ConvBNReLU_v5(num_filters_init*128, num_filters_init*64, 1,1,0, dropout=dropout),\n",
    "            ConvBNReLU_v5(num_filters_init*64, 128, 1,1,0,dropout=dropout),\n",
    "            ConvBNReLU_v5(128, output_size, 1,1,0),\n",
    "\n",
    "        )\n",
    "        # 全結合層\n",
    "        \"\"\"self.fc = nn.Sequential(\n",
    "            nn.Linear(num_filters_init*128, num_filters_init*64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_filters_init*64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(128, output_size)\n",
    "        )\"\"\"\n",
    "\n",
    "        #nn.init.kaiming_normal_(self.fc[0].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        #nn.init.kaiming_normal_(self.fc[3].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        \n",
    "\n",
    "        # 最後のConv1dにもHe初期化を適用\n",
    "        #nn.init.kaiming_normal_(self.cnn[-1].weight, mode='fan_out', nonlinearity='relu')\n",
    "        #if self.cnn[-1].bias is not None:\n",
    "        #    nn.init.constant_(self.cnn[-1].bias, 0)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x).view(x.size(0), -1)\n",
    "        #return self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v5(X, y=None, batch_size=1, shuffle=False):\n",
    "    if shuffle:\n",
    "        idxs = np.random.permutation(np.arange(len(X)))\n",
    "    else:\n",
    "        idxs = np.arange(len(X))\n",
    "    \n",
    "    #データセットをバッチサイズごとに分割\n",
    "    for i in range(0, len(idxs), batch_size):\n",
    "        idxs_batch = idxs[i:i+batch_size]\n",
    "        X_batch = X[idxs_batch].astype('f4')\n",
    "\n",
    "        X_batch = torch.from_numpy(X_batch)\n",
    "        if y is None:\n",
    "            yield X_batch\n",
    "        else:\n",
    "            y_batch = y[idxs_batch]\n",
    "            y_batch = torch.from_numpy(y_batch-1)\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "\n",
    "def forward_by_batches_v5(cnn, X):\n",
    "    Y = []\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in create_dataloader_v5(X, batch_size=1024, shuffle=False):\n",
    "            x = x.to(device)\n",
    "            Y.append(cnn(x))\n",
    "    cnn.train()\n",
    "\n",
    "    Y = torch.cat(Y) # Yをテンソルに変換\n",
    "    return Y\n",
    "\n",
    "\n",
    "def evaluate_model_v5(cnn, X, Y):\n",
    "    Y_pred = forward_by_batches_v5(cnn, X)\n",
    "    loss = F.cross_entropy(Y_pred, torch.from_numpy(Y-1.0).type(torch.int64).to(device)).item() # クロスエントロピー損失の計算 仕方なく0~7クラス分類とする\n",
    "\n",
    "    Y_pred = F.softmax(Y_pred, dim=1) \n",
    "    Y_pred = torch.argmax(Y_pred, dim=1)  # 最も高い確率のY_predのラベルを予測ラベルとしてY_predに入れられる。\n",
    "    Y_pred = Y_pred + 1  # 予測ラベルに1を加えて1~8の範囲に変換する\n",
    "    Y_pred = Y_pred.cpu().numpy()  # テンソルでGPUにのっているものをcpuに移動して、それをさらにnumpy配列に変換している。\n",
    "    kappa = metrics.cohen_kappa_score(Y, Y_pred) # 1~8クラス分類\n",
    "\n",
    "    return {'loss':loss, 'kappa':kappa, 'Y_pred':Y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_filters_init = 32\n",
    "in_channels = 3  \n",
    "output_size = len(np.unique(label))  #　これは分類するラベルの数。最終層の特徴量の数\n",
    "num_epoch = 5  # num of epochs (full loops though the training set)\n",
    "lr = 1e-3  # learning rate 3e-4だった\n",
    "\n",
    "\n",
    "model_save_path = \"../models/cnn_model_v5.pth\"\n",
    "cnn_v5 = CNN_v5(\n",
    "    output_size=output_size,\n",
    "    in_channels=in_channels,\n",
    "    num_filters_init=num_filters_init,\n",
    "    dropout=0.35\n",
    ").to(device)\n",
    "cnn_v5.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_v5(\n",
       "  (cnn): Sequential(\n",
       "    (0): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(3, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(8,), stride=(2,), padding=(3,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(6,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(6,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(1024, 2048, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(2048, 4096, kernel_size=(8,), stride=(1,))\n",
       "        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(4096, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): ConvBNReLU_v5(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(128, 8, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v5.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU_v4(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=True,\n",
    "            dropout=0.0 # ドロップアウト率を新規追加\n",
    "    ):\n",
    "        super(ConvBNReLU_v4, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=bias),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        if dropout > 0:\n",
    "            self.main.append(nn.Dropout(dropout))\n",
    "\n",
    "        # He初期化\n",
    "        nn.init.kaiming_normal_(self.main[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        if self.main[0].bias is not None:\n",
    "            nn.init.constant_(self.main[0].bias, 0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.main(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class CNN_v4(nn.Module):\n",
    "    def __init__(self, output_size=8, in_channels=3, num_filters_init=8, dropout=0.0):\n",
    "        super(CNN_v4, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            ConvBNReLU_v4(in_channels, num_filters_init, 3,1,1), # 500 -> 500\n",
    "            \n",
    "\n",
    "            ConvBNReLU_v4(num_filters_init, num_filters_init*2, 8,2,3,dropout=dropout ), # 500->250\n",
    "            \n",
    "            ConvBNReLU_v4(num_filters_init*2, num_filters_init*4, 6,2,2,dropout=dropout), # 250 -> 125 (248)\n",
    "            ConvBNReLU_v4(num_filters_init*4, num_filters_init*8,7,2,2, dropout=dropout), # 125 -> 62\n",
    "            ConvBNReLU_v4(num_filters_init*8, num_filters_init*16,6,2,1 , dropout=dropout), # 62 -> 30\n",
    "\n",
    "            ConvBNReLU_v4(num_filters_init*16, num_filters_init*32, 4, 2, 1, dropout=dropout), # 30 -> 15\n",
    "            ConvBNReLU_v4(num_filters_init*32, num_filters_init*64, 3, 2, 1, dropout=dropout), # 15->8\n",
    "\n",
    "            ConvBNReLU_v4(num_filters_init*64, num_filters_init*128, 8,1,0), # 8 -> 1 \n",
    "            #nn.Conv1d(num_filters_init*128, output_size, 1,1,0) #代わりに下の全結合層を導入\n",
    "        )\n",
    "        # 全結合層\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_filters_init*128, num_filters_init*64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_filters_init*64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc[0].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        nn.init.kaiming_normal_(self.fc[3].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        \n",
    "\n",
    "        # 最後のConv1dにもHe初期化を適用\n",
    "        #nn.init.kaiming_normal_(self.cnn[-1].weight, mode='fan_out', nonlinearity='relu')\n",
    "        #if self.cnn[-1].bias is not None:\n",
    "        #    nn.init.constant_(self.cnn[-1].bias, 0)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "        #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v4(X, y=None, batch_size=1, shuffle=False):\n",
    "    if shuffle:\n",
    "        idxs = np.random.permutation(np.arange(len(X)))\n",
    "    else:\n",
    "        idxs = np.arange(len(X))\n",
    "    \n",
    "    #データセットをバッチサイズごとに分割\n",
    "    for i in range(0, len(idxs), batch_size):\n",
    "        idxs_batch = idxs[i:i+batch_size]\n",
    "        X_batch = X[idxs_batch].astype('f4')\n",
    "\n",
    "        X_batch = torch.from_numpy(X_batch)\n",
    "        if y is None:\n",
    "            yield X_batch\n",
    "        else:\n",
    "            y_batch = y[idxs_batch]\n",
    "            y_batch = torch.from_numpy(y_batch-1)\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "\n",
    "def forward_by_batches_v4(cnn, X):\n",
    "    Y = []\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in create_dataloader_v4(X, batch_size=1024, shuffle=False):\n",
    "            x = x.to(device)\n",
    "            Y.append(cnn(x))\n",
    "    cnn.train()\n",
    "\n",
    "    Y = torch.cat(Y) # Yをテンソルに変換\n",
    "    return Y\n",
    "\n",
    "\n",
    "def evaluate_model_v4(cnn, X, Y):\n",
    "    Y_pred = forward_by_batches_v4(cnn, X)\n",
    "    loss = F.cross_entropy(Y_pred, torch.from_numpy(Y-1.0).type(torch.int64).to(device)).item() # クロスエントロピー損失の計算 仕方なく0~7クラス分類とする\n",
    "\n",
    "    Y_pred = F.softmax(Y_pred, dim=1) \n",
    "    Y_pred = torch.argmax(Y_pred, dim=1)  # 最も高い確率のY_predのラベルを予測ラベルとしてY_predに入れられる。\n",
    "    Y_pred = Y_pred + 1  # 予測ラベルに1を加えて1~8の範囲に変換する\n",
    "    Y_pred = Y_pred.cpu().numpy()  # テンソルでGPUにのっているものをcpuに移動して、それをさらにnumpy配列に変換している。\n",
    "    kappa = metrics.cohen_kappa_score(Y, Y_pred) # 1~8クラス分類\n",
    "\n",
    "    return {'loss':loss, 'kappa':kappa, 'Y_pred':Y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "num_filters_init = 32\n",
    "in_channels = 3  \n",
    "output_size = len(np.unique(label))  #　これは分類するラベルの数。最終層の特徴量の数\n",
    "num_epoch = 5  # num of epochs (full loops though the training set)\n",
    "lr = 1e-3  # learning rate 3e-4だった\n",
    "\n",
    "model_save_path = \"../models/cnn_model_v4.pth\"\n",
    "cnn_v4 = CNN_v4(\n",
    "    output_size=output_size,\n",
    "    in_channels=in_channels,\n",
    "    num_filters_init=num_filters_init,\n",
    "    dropout=0.35\n",
    ").to(device)\n",
    "cnn_v4.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_v4(\n",
       "  (cnn): Sequential(\n",
       "    (0): ConvBNReLU_v4(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(3, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBNReLU_v4(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(8,), stride=(2,), padding=(3,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBNReLU_v4(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(6,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ConvBNReLU_v4(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvBNReLU_v4(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(6,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ConvBNReLU_v4(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvBNReLU_v4(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(1024, 2048, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.35, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ConvBNReLU_v4(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(2048, 4096, kernel_size=(8,), stride=(1,))\n",
       "        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.35, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.35, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v4.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU_v7(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=True,\n",
    "            dropout=0.0 # ドロップアウト率を新規追加\n",
    "    ):\n",
    "        super(ConvBNReLU_v7, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=bias),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        if dropout > 0:\n",
    "            self.main.append(nn.Dropout(dropout))\n",
    "\n",
    "        # He初期化\n",
    "        nn.init.kaiming_normal_(self.main[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        if self.main[0].bias is not None:\n",
    "            nn.init.constant_(self.main[0].bias, 0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.main(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class CNN_v7(nn.Module):\n",
    "    def __init__(self, output_size=8, in_channels=3, num_filters_init=8, dropout=0.0):\n",
    "        super(CNN_v7, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            ConvBNReLU_v7(in_channels, num_filters_init, 3,1,1), # 500 -> 500\n",
    "            ConvBNReLU_v7(num_filters_init, num_filters_init*2, 8,2,3,dropout=dropout ), # 500->250\n",
    "            ConvBNReLU_v7(num_filters_init*2, num_filters_init*3, 6,2,2,dropout=dropout), # 250 -> 125 (248)\n",
    "            ConvBNReLU_v7(num_filters_init*3, num_filters_init*3,7,2,2, dropout=dropout), # 125 -> 62\n",
    "            ConvBNReLU_v7(num_filters_init*3, num_filters_init*4,6,2,1 , dropout=dropout), # 62 -> 30\n",
    "            ConvBNReLU_v7(num_filters_init*4, num_filters_init*4, 4, 2, 1, dropout=dropout), # 30 -> 15\n",
    "            ConvBNReLU_v7(num_filters_init*4, num_filters_init*4, 3, 2, 1, dropout=dropout), # 15->8\n",
    "            ConvBNReLU_v7(num_filters_init*4, num_filters_init*4, 8,1,0, dropout=dropout), # 8 -> 1 \n",
    "            #nn.Conv1d(num_filters_init*128, output_size, 1,1,0) #代わりに下の全結合層を導入\n",
    "        )\n",
    "        # 全結合層\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_filters_init*4, num_filters_init*2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_filters_init*2, num_filters_init),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(num_filters_init, output_size)\n",
    "        )\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc[0].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        nn.init.kaiming_normal_(self.fc[3].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        #nn.init.kaiming_normal_(self.fc[6].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        \n",
    "        \n",
    "\n",
    "        # 最後のConv1dにもHe初期化を適用\n",
    "        #nn.init.kaiming_normal_(self.cnn[-1].weight, mode='fan_out', nonlinearity='relu')\n",
    "        #if self.cnn[-1].bias is not None:\n",
    "        #    nn.init.constant_(self.cnn[-1].bias, 0)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "        #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v7(X, y=None, batch_size=1, shuffle=False):\n",
    "    if shuffle:\n",
    "        idxs = np.random.permutation(np.arange(len(X)))\n",
    "    else:\n",
    "        idxs = np.arange(len(X))\n",
    "    \n",
    "    #データセットをバッチサイズごとに分割\n",
    "    for i in range(0, len(idxs), batch_size):\n",
    "        idxs_batch = idxs[i:i+batch_size]\n",
    "        X_batch = X[idxs_batch].astype('f4')\n",
    "\n",
    "        X_batch = torch.from_numpy(X_batch)\n",
    "        if y is None:\n",
    "            yield X_batch\n",
    "        else:\n",
    "            y_batch = y[idxs_batch]\n",
    "            y_batch = torch.from_numpy(y_batch-1)\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "\n",
    "def forward_by_batches_v7(cnn, X):\n",
    "    Y = []\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in create_dataloader_v7(X, batch_size=1024, shuffle=False):\n",
    "            x = x.to(device)\n",
    "            Y.append(cnn(x))\n",
    "    cnn.train()\n",
    "\n",
    "    Y = torch.cat(Y) # Yをテンソルに変換\n",
    "    return Y\n",
    "\n",
    "\n",
    "def evaluate_model_v7(cnn, X, Y):\n",
    "    Y_pred = forward_by_batches_v7(cnn, X)\n",
    "    loss = F.cross_entropy(Y_pred, torch.from_numpy(Y-1.0).type(torch.int64).to(device)).item() # クロスエントロピー損失の計算 仕方なく0~7クラス分類とする\n",
    "\n",
    "    Y_pred = F.softmax(Y_pred, dim=1) \n",
    "    Y_pred = torch.argmax(Y_pred, dim=1)  # 最も高い確率のY_predのラベルを予測ラベルとしてY_predに入れられる。\n",
    "    Y_pred = Y_pred + 1  # 予測ラベルに1を加えて1~8の範囲に変換する\n",
    "    Y_pred = Y_pred.cpu().numpy()  # テンソルでGPUにのっているものをcpuに移動して、それをさらにnumpy配列に変換している。\n",
    "    kappa = metrics.cohen_kappa_score(Y, Y_pred) # 1~8クラス分類\n",
    "\n",
    "    return {'loss':loss, 'kappa':kappa, 'Y_pred':Y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "num_filters_init = 25 # 16:    32:0.85(test limit)\n",
    "in_channels = 3  \n",
    "output_size = len(np.unique(label))  #　これは分類するラベルの数。最終層の特徴量の数\n",
    "num_epoch = 5  # num of epochs (full loops though the training set)\n",
    "lr = 1e-3  # learning rate 3e-4だった\n",
    "\n",
    "\n",
    "model_save_path = \"../models/cnn_v7_all.pth\"\n",
    "cnn_v7 = CNN_v7(\n",
    "    output_size=output_size,\n",
    "    in_channels=in_channels,\n",
    "    num_filters_init=num_filters_init,\n",
    "    dropout=0.2 # filter=32, dropout0.3\n",
    ").to(device)\n",
    "cnn_v7.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_v7(\n",
       "  (cnn): Sequential(\n",
       "    (0): ConvBNReLU_v7(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(3, 25, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBNReLU_v7(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(25, 50, kernel_size=(8,), stride=(2,), padding=(3,))\n",
       "        (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBNReLU_v7(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(50, 75, kernel_size=(6,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ConvBNReLU_v7(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(75, 75, kernel_size=(7,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvBNReLU_v7(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(75, 100, kernel_size=(6,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ConvBNReLU_v7(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(100, 100, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvBNReLU_v7(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(100, 100, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ConvBNReLU_v7(\n",
       "      (main): Sequential(\n",
       "        (0): Conv1d(100, 100, kernel_size=(8,), stride=(1,))\n",
       "        (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=25, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=25, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_v7.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_v4 = evaluate_model_v4(cnn_v4, xyz, label)\n",
    "result_v5 = evaluate_model_v5(cnn_v5, xyz, label)\n",
    "result_v7 = evaluate_model_v7(cnn_v7, xyz, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier performance v4\n",
      "Out of sample:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.27      0.91      0.41      5967\n",
      "         2.0       0.81      0.23      0.36      5225\n",
      "         3.0       0.97      0.52      0.67       555\n",
      "         4.0       0.92      0.26      0.41      2407\n",
      "         5.0       0.10      0.01      0.03      4095\n",
      "         6.0       0.18      0.11      0.14      1836\n",
      "         7.0       0.20      0.18      0.19      4362\n",
      "         8.0       0.25      0.02      0.03      4342\n",
      "\n",
      "    accuracy                           0.30     28789\n",
      "   macro avg       0.46      0.28      0.28     28789\n",
      "weighted avg       0.39      0.30      0.24     28789\n",
      "\n",
      "\n",
      "Classifier performance v5\n",
      "Out of sample:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.26      0.93      0.40      5967\n",
      "         2.0       0.89      0.35      0.51      5225\n",
      "         3.0       0.96      0.54      0.69       555\n",
      "         4.0       0.95      0.29      0.45      2407\n",
      "         5.0       0.06      0.01      0.02      4095\n",
      "         6.0       0.12      0.03      0.05      1836\n",
      "         7.0       0.21      0.11      0.15      4362\n",
      "         8.0       0.15      0.01      0.02      4342\n",
      "\n",
      "    accuracy                           0.31     28789\n",
      "   macro avg       0.45      0.29      0.29     28789\n",
      "weighted avg       0.38      0.31      0.26     28789\n",
      "\n",
      "\n",
      "Classifier performance v7\n",
      "Out of sample:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.47      0.56      0.51      5967\n",
      "         2.0       0.96      0.46      0.63      5225\n",
      "         3.0       0.93      0.50      0.65       555\n",
      "         4.0       0.15      0.68      0.25      2407\n",
      "         5.0       0.37      0.05      0.09      4095\n",
      "         6.0       0.30      0.34      0.32      1836\n",
      "         7.0       0.27      0.22      0.24      4362\n",
      "         8.0       0.44      0.21      0.28      4342\n",
      "\n",
      "    accuracy                           0.36     28789\n",
      "   macro avg       0.49      0.38      0.37     28789\n",
      "weighted avg       0.48      0.36      0.36     28789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassifier performance v4')\n",
    "print('Out of sample:\\n', metrics.classification_report(label, result_v4['Y_pred']))\n",
    "print('\\nClassifier performance v5')\n",
    "print('Out of sample:\\n', metrics.classification_report(label, result_v5['Y_pred']))\n",
    "print('\\nClassifier performance v7')\n",
    "print('Out of sample:\\n', metrics.classification_report(label, result_v7['Y_pred']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo_Okita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
