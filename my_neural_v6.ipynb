{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここではモデルロードがちゃんとできるかを試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42) # 乱数生成シード\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Grab a GPU if there is one\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using {} device: {}\".format(device, torch.cuda.current_device()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196072, 3, 500)\n",
      "(196072,)\n"
     ]
    }
   ],
   "source": [
    "fold = \"../train_raw_npy/\"\n",
    "xyz = np.load(f\"{fold}acc_xyz.npy\")\n",
    "label = np.load(f\"{fold}sampled_label.npy\")\n",
    "print(xyz.shape)\n",
    "print(label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0    7731\n",
       "8.0    5829\n",
       "4.0    5305\n",
       "5.0    3999\n",
       "2.0    3749\n",
       "1.0    3420\n",
       "6.0    3417\n",
       "3.0    1110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#おしり3万データを使う  \n",
    "xyz = xyz[0:17280*2,:]\n",
    "label = label[0:17280*2]\n",
    "xyz.shape\n",
    "pd.Series(label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (27648, 3, 500)\n",
      "Test data shape: (6912, 3, 500)\n",
      "Train label shape: (27648,)\n",
      "Test label shape: (6912,)\n",
      "7.0    6213\n",
      "8.0    4661\n",
      "4.0    4236\n",
      "5.0    3205\n",
      "2.0    2984\n",
      "1.0    2738\n",
      "6.0    2730\n",
      "3.0     881\n",
      "Name: count, dtype: int64\n",
      "7.0    1518\n",
      "8.0    1168\n",
      "4.0    1069\n",
      "5.0     794\n",
      "2.0     765\n",
      "6.0     687\n",
      "1.0     682\n",
      "3.0     229\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ランダムサンプリング\n",
    "train_xyz, test_xyz, train_label, test_label = train_test_split(xyz, label, test_size=0.2, shuffle=True,random_state=40)\n",
    "\n",
    "# 結果の確認\n",
    "print(f\"Train data shape: {train_xyz.shape}\")\n",
    "print(f\"Test data shape: {test_xyz.shape}\")\n",
    "print(f\"Train label shape: {train_label.shape}\")\n",
    "print(f\"Test label shape: {test_label.shape}\")\n",
    "print(pd.Series(train_label).value_counts())\n",
    "print(pd.Series(test_label).value_counts())\n",
    "# train_randomの生成\n",
    "train_xyz_random = train_xyz\n",
    "train_label_random = train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(X, y=None, batch_size=1, shuffle=False):\n",
    "    if shuffle:\n",
    "        idxs = np.random.permutation(np.arange(len(X)))\n",
    "    else:\n",
    "        idxs = np.arange(len(X))\n",
    "    \n",
    "    #データセットをバッチサイズごとに分割\n",
    "    for i in range(0, len(idxs), batch_size):\n",
    "        idxs_batch = idxs[i:i+batch_size]\n",
    "        X_batch = X[idxs_batch].astype('f4')\n",
    "\n",
    "        X_batch = torch.from_numpy(X_batch)\n",
    "        if y is None:\n",
    "            yield X_batch\n",
    "        else:\n",
    "            y_batch = y[idxs_batch]\n",
    "            y_batch = torch.from_numpy(y_batch-1)\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "\n",
    "def forward_by_batches(cnn, X):\n",
    "    Y = []\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in create_dataloader(X, batch_size=1024, shuffle=False):\n",
    "            x = x.to(device)\n",
    "            Y.append(cnn(x))\n",
    "    cnn.train()\n",
    "\n",
    "    Y = torch.cat(Y) # Yをテンソルに変換\n",
    "    return Y\n",
    "\n",
    "\n",
    "def evaluate_model(cnn, X, Y):\n",
    "    Y_pred = forward_by_batches(cnn, X)\n",
    "    loss = F.cross_entropy(Y_pred, torch.from_numpy(Y-1.0).type(torch.int64).to(device)).item() # クロスエントロピー損失の計算 仕方なく0~7クラス分類とする\n",
    "\n",
    "    Y_pred = F.softmax(Y_pred, dim=1) \n",
    "    Y_pred = torch.argmax(Y_pred, dim=1)  # 最も高い確率のY_predのラベルを予測ラベルとしてY_predに入れられる。\n",
    "    Y_pred = Y_pred + 1  # 予測ラベルに1を加えて1~8の範囲に変換する\n",
    "    Y_pred = Y_pred.cpu().numpy()  # テンソルでGPUにのっているものをcpuに移動して、それをさらにnumpy配列に変換している。\n",
    "    kappa = metrics.cohen_kappa_score(Y, Y_pred) # 1~8クラス分類\n",
    "\n",
    "    return {'loss':loss, 'kappa':kappa, 'Y_pred':Y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=True,\n",
    "            dropout=0.0 # ドロップアウト率を新規追加\n",
    "    ):\n",
    "        super(ConvBNReLU, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=bias),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        if dropout > 0:\n",
    "            self.main.append(nn.Dropout(dropout))\n",
    "\n",
    "        # He初期化\n",
    "        nn.init.kaiming_normal_(self.main[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        if self.main[0].bias is not None:\n",
    "            nn.init.constant_(self.main[0].bias, 0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.main(x)\n",
    "    \n",
    "\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, output_size=8, in_channels=3, num_filters_init=8, dropout=0.0):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            ConvBNReLU(in_channels, num_filters_init, 3,1,1), # 500 -> 500\n",
    "            \n",
    "\n",
    "            ConvBNReLU(num_filters_init, num_filters_init*2, 8,2,3,dropout=dropout ), # 500->250\n",
    "            \n",
    "            ConvBNReLU(num_filters_init*2, num_filters_init*4, 6,2,2,dropout=dropout), # 250 -> 125 (248)\n",
    "            ConvBNReLU(num_filters_init*4, num_filters_init*8,7,2,2, dropout=dropout), # 125 -> 62\n",
    "            ConvBNReLU(num_filters_init*8, num_filters_init*16,6,2,1 , dropout=dropout), # 62 -> 30\n",
    "\n",
    "            ConvBNReLU(num_filters_init*16, num_filters_init*32, 4, 2, 1, dropout=dropout), # 30 -> 15\n",
    "            ConvBNReLU(num_filters_init*32, num_filters_init*64, 3, 2, 1, dropout=dropout), # 15->8\n",
    "\n",
    "            ConvBNReLU(num_filters_init*64, num_filters_init*128, 8,1,0), # 8 -> 1 \n",
    "            #nn.Conv1d(num_filters_init*128, output_size, 1,1,0) #代わりに下の全結合層を導入\n",
    "        )\n",
    "        # 全結合層\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_filters_init*128, num_filters_init*64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_filters_init*64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc[0].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        nn.init.kaiming_normal_(self.fc[3].weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        \n",
    "\n",
    "        # 最後のConv1dにもHe初期化を適用\n",
    "        #nn.init.kaiming_normal_(self.cnn[-1].weight, mode='fan_out', nonlinearity='relu')\n",
    "        #if self.cnn[-1].bias is not None:\n",
    "        #    nn.init.constant_(self.cnn[-1].bias, 0)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "        #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (cnn): Sequential(\n",
      "    (0): ConvBNReLU(\n",
      "      (main): Sequential(\n",
      "        (0): Conv1d(3, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ConvBNReLU(\n",
      "      (main): Sequential(\n",
      "        (0): Conv1d(32, 64, kernel_size=(8,), stride=(2,), padding=(3,))\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout(p=0.35, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ConvBNReLU(\n",
      "      (main): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(6,), stride=(2,), padding=(2,))\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout(p=0.35, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ConvBNReLU(\n",
      "      (main): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(2,))\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout(p=0.35, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBNReLU(\n",
      "      (main): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(6,), stride=(2,), padding=(1,))\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout(p=0.35, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): ConvBNReLU(\n",
      "      (main): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout(p=0.35, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): ConvBNReLU(\n",
      "      (main): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Dropout(p=0.35, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): ConvBNReLU(\n",
      "      (main): Sequential(\n",
      "        (0): Conv1d(2048, 4096, kernel_size=(8,), stride=(1,))\n",
      "        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.35, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.35, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_filters_init = 32\n",
    "in_channels = 3  \n",
    "output_size = len(np.unique(train_label_random))  #　これは分類するラベルの数。最終層の特徴量の数\n",
    "\n",
    "cnn = CNN(\n",
    "    output_size=output_size,\n",
    "    in_channels=in_channels,\n",
    "    num_filters_init=num_filters_init,\n",
    "    dropout=0.35\n",
    ").to(device)\n",
    "print(cnn) # ここではcnnのネットワーク構造の定義をして、そのネットワークの構造をprintしている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.load_state_dict(torch.load(\"../models/cnn_model_v4.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier performance\n",
      "Out of sample:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.70      0.87      0.78      1041\n",
      "         2.0       0.99      0.93      0.96       719\n",
      "         3.0       1.00      0.99      1.00       243\n",
      "         4.0       0.99      0.96      0.98       960\n",
      "         5.0       0.95      0.84      0.89       774\n",
      "         6.0       0.85      0.89      0.87       926\n",
      "         7.0       0.76      0.73      0.75       964\n",
      "         8.0       0.75      0.53      0.62       373\n",
      "\n",
      "    accuracy                           0.85      6000\n",
      "   macro avg       0.87      0.84      0.86      6000\n",
      "weighted avg       0.86      0.85      0.85      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(cnn, test_xyz, test_label)\n",
    "\n",
    "# Report\n",
    "#Y_test_pred_lab = le.inverse_transform(results['Y_pred'])  # back to text labels\n",
    "#Y_test_lab = le.inverse_transform(test_label)  # back to text labels\n",
    "print('\\nClassifier performance')\n",
    "print('Out of sample:\\n', metrics.classification_report(test_label, results['Y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labo_Okita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
